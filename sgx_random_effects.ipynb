{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Effects Estimation of the determinants of leverage amongst SGX listed companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import RegressionResults\n",
    "from linearmodels.panel import RandomEffects\n",
    "from linearmodels.panel.results import PanelResults, RandomEffectsResults, PanelEffectsResults\n",
    "\n",
    "from statsmodels.iolib import load_pickle, save_pickle\n",
    "\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the SGX Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgx = pd.read_csv(\"data/clean_sgx.csv\")\n",
    "sgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgx = sgx.set_index(['Company Code', 'Year'], drop= False)\n",
    "\n",
    "sgx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Effects Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Way Random Effects Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-Way Entity Random Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "endo = sgx[endo_var]\n",
    "exog = sm.add_constant(sgx[exog_vars])\n",
    "\n",
    "entity_re_mod = RandomEffects(endo, exog)\n",
    "\n",
    "entity_re_fit = entity_re_mod.fit()\n",
    "\n",
    "print(entity_re_fit.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-Way Time Random Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgx = sgx.swaplevel('Year', 'Company Code')\n",
    "\n",
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "endo = sgx[endo_var]\n",
    "exog = sm.add_constant(sgx[exog_vars])\n",
    "\n",
    "time_re_mod = RandomEffects(endo, exog)\n",
    "\n",
    "time_re_fit = time_re_mod.fit()\n",
    "\n",
    "print(time_re_fit.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Way Random Effects Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feasible Generalised Least Square Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighting_matrix(time_panels: pd.Series, entity_panels: pd.Series):\n",
    "    t = time_panels.nunique()\n",
    "    n = entity_panels.nunique()\n",
    "    \n",
    "    J_n_bar = (1 / n) * np.ones(shape = (n, n))\n",
    "    J_t_bar = (1 / t) * np.ones(shape = (t, t))\n",
    "    I_n = np.identity(n = n)\n",
    "    I_t = np.identity(n = t)\n",
    "\n",
    "    E_n = I_n - J_n_bar\n",
    "    E_t = I_t - J_t_bar\n",
    "\n",
    "    Q_1 = np.kron(E_n, E_t)\n",
    "    Q_2 = np.kron(E_n, J_t_bar)\n",
    "    Q_3 = np.kron(J_n_bar, E_t)\n",
    "    Q_4 = np.kron(J_n_bar, J_t_bar)\n",
    "    \n",
    "    return np.array([Q_1, Q_2, Q_3, Q_4])\n",
    "\n",
    "def get_omega_i(weighting_matrix: np.array, resid: np.array):\n",
    "\n",
    "    w_1 = (resid.T @ weighting_matrix[0] @ resid) / np.trace(weighting_matrix[0])\n",
    "    w_2 = (resid.T @ weighting_matrix[1] @ resid) / np.trace(weighting_matrix[1])\n",
    "    w_3 = (resid.T @ weighting_matrix[2] @ resid) / np.trace(weighting_matrix[2])\n",
    "    w_4 = w_2 + w_3 - w_1\n",
    "\n",
    "    return np.array([w_1, w_2, w_3, w_4])\n",
    "\n",
    "def get_rcorr_matrix(omega_matrix: np.array, weighting_matrix: np.array):\n",
    "    omega = omega_matrix\n",
    "    weight = weighting_matrix\n",
    "    return omega[0] * weight[0] + omega[1] * weight[1] + omega[2] * weight[2] + omega[3] * weight[3]\n",
    "\n",
    "def TwoWayRandomEffects(Y: pd.Series, X: Union[pd.Series, pd.DataFrame], entity_panel: pd.Series, time_panel: pd.Series, epsilon: float= 0.0001, maxiter: int= 99):\n",
    "    # Step 1: Run OLS of Y on X\n",
    "    ols = sm.OLS(Y, X)\n",
    "    residuals = ols.fit().resid\n",
    "    # Step 2: Get OLS weighting matrix\n",
    "    weight_matrix = get_weighting_matrix(time_panels= time_panel, entity_panels= entity_panel)\n",
    "    omega_matrix = get_omega_i(weight_matrix, residuals)\n",
    "    OMEGA = get_rcorr_matrix(omega_matrix, weight_matrix)\n",
    "    \n",
    "    # Step 3: Get GLS residuals using weighting matrix\n",
    "    gls = sm.GLS(endog= Y, exog= X, sigma= OMEGA)\n",
    "    gls_residuals = gls.fit().resid\n",
    "    # Step 4: Update GLS weighting matrix\n",
    "    weight_matrix = get_weighting_matrix(time_panels= time_panel, entity_panels= entity_panel)\n",
    "    omega_matrix = get_omega_i(weight_matrix, gls_residuals)\n",
    "    OMEGA = get_rcorr_matrix(omega_matrix, weight_matrix)\n",
    "    # Step 5: Update GLS coefficient estimates\n",
    "    init_gls = ols ## Initial GLS model\n",
    "    iter_gls = sm.GLS(endog= Y, exog= X, sigma= OMEGA) ## Updated GLS model\n",
    "\n",
    "    i = 1\n",
    "    while np.max(abs(init_gls.fit().params - iter_gls.fit().params)) >= epsilon: ## If there is a significant difference in the model estimates, re-run the refining steps\n",
    "        init_gls = iter_gls ## Set the initial GLS model to the most updated model\n",
    "        # Step 3: Get GLS residuals using weighting matrix\n",
    "        gls = sm.GLS(endog= Y, exog= X, sigma= OMEGA)\n",
    "        gls_residuals = gls.fit().resid\n",
    "        # Step 4: Update GLS weighting matrix\n",
    "        weight_matrix = get_weighting_matrix(time_panels= time_panel, entity_panels= entity_panel)\n",
    "        omega_matrix = get_omega_i(weight_matrix, gls_residuals)\n",
    "        OMEGA = get_rcorr_matrix(omega_matrix, weight_matrix)\n",
    "        # Step 5: Update GLS coefficient estimates\n",
    "        iter_gls = sm.GLS(endog= Y, exog= X, sigma= OMEGA) ## Produce an updated GLS model\n",
    "        i += 1\n",
    "        if i == maxiter:\n",
    "            print(f\"Maximum of {maxiter} iterations reached before model convergence was achieved.\")\n",
    "            break\n",
    "\n",
    "    print(f\"{i} iterations of GLS re-specification performed\")\n",
    "    return gls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgx = sgx.swaplevel('Company Code', 'Year')\n",
    "\n",
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "endo = sgx[endo_var]\n",
    "exog = sm.add_constant(sgx[exog_vars])\n",
    "\n",
    "entity_panel = sgx['Company Code']\n",
    "time_panel = sgx['Year']\n",
    "\n",
    "tw_re_mod = TwoWayRandomEffects(endo, exog, entity_panel, time_panel)\n",
    "\n",
    "tw_re_fit = tw_re_mod.fit()\n",
    "\n",
    "print(tw_re_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for significance of Random Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagrange Multiplier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_LM_stat(restricted_model: PanelResults, how: str): \n",
    "    T = restricted_model.time_info.total.astype('int')\n",
    "    n = restricted_model.entity_info.total.astype('int')\n",
    "\n",
    "    J_n = np.ones(shape = (n, n))\n",
    "    J_T = np.ones(shape = (T, T))\n",
    "\n",
    "    I_n = np.identity(n = n)\n",
    "    I_T = np.identity(n = T)\n",
    "\n",
    "    u_tilda = restricted_model.resids\n",
    "    \n",
    "    if how.lower() == 'entity':\n",
    "        LM_C_entity = ((n * T) / (2 * (T - 1))) * (1 - ((u_tilda.T @ np.kron(I_n, J_T) @ u_tilda) / (u_tilda.T @ u_tilda))) ** 2\n",
    "        return LM_C_entity\n",
    "    elif how.lower() == 'time':\n",
    "        LM_C_time = ((n * T) / (2 * (n - 1))) * (1 - ((u_tilda.T @ np.kron(J_n, I_T) @ u_tilda) / (u_tilda.T @ u_tilda))) ** 2\n",
    "        return LM_C_time\n",
    "    else:\n",
    "        raise ValueError(f\"'how' parameter should be either 'Entity' or 'Time' and not {how}.\")\n",
    "    \n",
    "def marg_LM_stat(restricted_model: RandomEffectsResults, how: str): \n",
    "    if how.lower() == 'time':    \n",
    "        T = restricted_model.time_info.total.astype('int')\n",
    "        n = restricted_model.entity_info.total.astype('int')\n",
    "    elif how.lower() == 'entity':\n",
    "        n = restricted_model.time_info.total.astype('int')\n",
    "        T = restricted_model.entity_info.total.astype('int')\n",
    "    else:\n",
    "        raise ValueError(f\"'how' parameter should be either 'Entity' or 'Time' and not {how}.\")\n",
    "\n",
    "    J_n = np.ones(shape = (n, n))\n",
    "    J_T = np.ones(shape = (T, T))\n",
    "    \n",
    "    J_n_bar = (1 / n) * J_n\n",
    "    J_T_bar = (1 / T) * J_T\n",
    "\n",
    "    I_n = np.identity(n = n)\n",
    "    I_T = np.identity(n = T)\n",
    "\n",
    "    E_n = I_n - J_n_bar\n",
    "    E_T = I_T - J_T_bar\n",
    "\n",
    "    u_tilda = restricted_model.resids\n",
    "\n",
    "    if how.lower() == 'entity':\n",
    "        sigma_v_sq = (1 / T*(n - 1)) * u_tilda.T @ np.kron(E_n, I_T) @ u_tilda\n",
    "        sigma_2_sq = (1 / T) * u_tilda.T @ np.kron(J_n_bar, I_T) @ u_tilda\n",
    "\n",
    "        Q_1 = (1 / sigma_2_sq) * u_tilda.T @ np.kron(J_n_bar, J_T_bar) @ u_tilda\n",
    "        Q_2 = (1 / (n - 1)*sigma_v_sq) * u_tilda.T @ np.kron(E_n, J_T_bar) @ u_tilda\n",
    "\n",
    "        LM_M_entity = ((np.sqrt(T) * sigma_2_sq * sigma_v_sq) / np.sqrt(2 * (T - 1) * (sigma_v_sq ** 2 + (n - 1) * sigma_2_sq ** 2))) *\\\n",
    "             ((1/sigma_2_sq) * (Q_1 - 1) + ((n-1) / sigma_v_sq) * (Q_2 - 1))\n",
    "        \n",
    "        return LM_M_entity\n",
    "    \n",
    "    else:\n",
    "        sigma_v_sq = (1 / T*(n - 1)) * u_tilda.T @ np.kron(I_n, E_T) @ u_tilda\n",
    "        sigma_1_sq = (1 / n) * u_tilda.T @ np.kron(I_n, J_T_bar) @ u_tilda\n",
    "\n",
    "        R_1 = (1 / sigma_1_sq) * u_tilda.T @ np.kron(J_T_bar, J_n_bar) @ u_tilda\n",
    "        R_2 = (1 / (T - 1)*sigma_v_sq) * u_tilda.T @ np.kron(J_n_bar, E_T) @ u_tilda\n",
    "\n",
    "        LM_M_time = ((np.sqrt(n) * sigma_1_sq * sigma_v_sq) / np.sqrt(2 * (n - 1) * (sigma_v_sq ** 2 + (T - 1) * sigma_1_sq ** 2))) *\\\n",
    "             ((1/sigma_1_sq) * (R_1 - 1) + ((T-1) / sigma_v_sq) * (R_2 - 1))\n",
    "        \n",
    "        return LM_M_time\n",
    "\n",
    "def joint_LM_stat(restricted_model: PanelResults): \n",
    "    return cond_LM_stat(restricted_model, 'Entity') + cond_LM_stat(restricted_model, 'Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint LM-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_ols_res = load_pickle('model/pooled_ols.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_stat = joint_LM_stat(pooled_ols_res)\n",
    "\n",
    "joint_p = 1 - stats.chi2.cdf(joint_stat, 1)\n",
    "\n",
    "print(f\"Joint LM Statistic for 2-way Random Effects: {joint_stat}\")\n",
    "print(f\"p-value of Joint LM test for 2-way Random Effects: {joint_p}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional LM-Test for Entity Random Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_entity_stat = cond_LM_stat(pooled_ols_res, how= 'entity')\n",
    "\n",
    "cond_entity_p = 1 - stats.chi2.cdf(cond_entity_stat, 1)\n",
    "\n",
    "print(f\"Conditional LM Statistic for Entity Random Effects: {cond_entity_stat}\")\n",
    "print(f\"p-value of Conditional LM test for Entity Random ffects: {cond_entity_p}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional LM-Test for Time Random Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_time_stat = cond_LM_stat(pooled_ols_res, how= 'time')\n",
    "\n",
    "cond_time_p = 1 - stats.chi2.cdf(cond_time_stat, 1)\n",
    "\n",
    "print(f\"Conditional LM Statistic for Time Random Effects: {cond_time_stat}\")\n",
    "print(f\"p-value of Conditional LM test for Time Random Effects: {cond_time_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marginal LM-Test for Entity Random Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_entity_stat = marg_LM_stat(time_re_fit, how= 'entity')\n",
    "\n",
    "marg_entity_p = 1 - stats.chi2.cdf(marg_entity_stat, 1)\n",
    "\n",
    "print(f\"Marginal LM Statistic for Entity Random Effects: {marg_entity_stat}\")\n",
    "print(f\"p-value of Marginal LM test for Entity Random ffects: {marg_entity_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_time_stat = marg_LM_stat(entity_re_fit, how= 'time')\n",
    "\n",
    "marg_time_p = stats.chi2.cdf(marg_time_stat, 1)\n",
    "\n",
    "print(f\"Marginal LM Statistic for Time Random Effects: {marg_time_stat}\")\n",
    "print(f\"p-value of Marginal LM test for Time Random ffects: {marg_time_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of the LM-test, only the joint LM and conditional LM test for entity effects were significant. However, the significance of the joint LM test is powered by the significance of the conditional LM test for entity as can be seen from the insignificance of the marginal LM tests. Thus, we should strongly consider the 1-way entity random effects model over the 2-way random effects model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-Likelihood Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_test(restricted_model: PanelResults|RandomEffectsResults|PanelEffectsResults, unrestricted_model: PanelResults|RandomEffectsResults|PanelEffectsResults, df: int= 1):\n",
    "    try:\n",
    "        res_loglik = restricted_model.loglik\n",
    "    except:\n",
    "        res_loglik = restricted_model.llf\n",
    "\n",
    "    try:\n",
    "        unres_loglik = unrestricted_model.loglik\n",
    "    except:\n",
    "        unres_loglik = unrestricted_model.llf\n",
    "\n",
    "\n",
    "    lr_stat = -2 * (res_loglik - unres_loglik)\n",
    "        \n",
    "    lr_p = 1 - stats.chi2.cdf(lr_stat, df)\n",
    "\n",
    "    print(f\"Log-Likelihood Test Statistic: {lr_stat}\")\n",
    "    print(f\"Log-Likelihood Test Statistic: {lr_p}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Entity LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test(pooled_ols_res, entity_re_fit, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Time LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test(pooled_ols_res, time_re_fit, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test(pooled_ols_res, tw_re_fit, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Time LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test(entity_re_fit, tw_re_fit, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Time LR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test(time_re_fit, tw_re_fit, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Random Effects Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated Entity Random Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "endo = sgx[endo_var]\n",
    "\n",
    "mean_exog_vars = ['avg' + var for var in exog_vars]\n",
    "sgx[mean_exog_vars] = sgx[exog_vars].groupby(level= 'Company Code').transform('mean')\n",
    "\n",
    "exog = sm.add_constant(sgx[exog_vars + mean_exog_vars])\n",
    "\n",
    "entity_cre_mod = RandomEffects(endo, exog)\n",
    "\n",
    "entity_cre_fit = entity_cre_mod.fit()\n",
    "\n",
    "print(entity_cre_fit.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated 2-Way Random Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "endo = sgx[endo_var]\n",
    "\n",
    "mean_exog_vars = ['avg' + var for var in exog_vars]\n",
    "sgx[mean_exog_vars] = sgx[exog_vars].groupby(level= 'Company Code').transform('mean')\n",
    "\n",
    "exog = sm.add_constant(sgx[exog_vars + mean_exog_vars])\n",
    "\n",
    "entity_panel, time_panel = sgx['Company Code'], sgx['Year']\n",
    "\n",
    "tw_cre_mod = TwoWayRandomEffects(endo, exog, entity_panel, time_panel)\n",
    "\n",
    "tw_cre_fit = tw_cre_mod.fit()\n",
    "\n",
    "print(tw_cre_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hausman Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausman_test(fixed_effects: PanelEffectsResults, random_effects: RandomEffectsResults|RegressionResults):    \n",
    "    # (I) find overlapping coefficients:\n",
    "    common_coef = list(set(fixed_effects.params.index).intersection(random_effects.params.index))\n",
    "\n",
    "    # (II) calculate differences between FE and RE:\n",
    "    b_diff = np.array(fixed_effects.params[common_coef] - random_effects.params[common_coef])\n",
    "    df = len(b_diff)\n",
    "    b_diff.reshape((df, 1))\n",
    "    \n",
    "    b_fe_cov = fixed_effects.cov\n",
    "    try:\n",
    "        b_re_cov = random_effects.cov\n",
    "    except:\n",
    "        b_re_cov = random_effects.cov_params()\n",
    "\n",
    "    b_cov_diff = np.array(b_fe_cov.loc[common_coef, common_coef] -\n",
    "                        b_re_cov.loc[common_coef, common_coef])\n",
    "    b_cov_diff.reshape((df, df))\n",
    "\n",
    "    # (III) calculate test statistic:\n",
    "    hausman_stat = abs(np.transpose(b_diff) @ np.linalg.inv(b_cov_diff) @ b_diff)\n",
    "    hausman_p = 1 - stats.chi2.cdf(hausman_stat, df)\n",
    "\n",
    "    print(f\"Hausman Test Statistic: {hausman_stat}\")\n",
    "    print(f\"Hausman Test Statistic: {hausman_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_fe_fit = load_pickle('model/two_way_fe.pickle')\n",
    "\n",
    "entity_fe_fit = load_pickle('model/entity_fe.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-way FE vs. 2-way RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hausman_test(tw_fe_fit, tw_re_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity FE vs. Entity RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hausman_test(entity_fe_fit, entity_re_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Hausman tests conducted, the p-values of all tests are significant at all reasonable levels of significance. Thus, a fixed effects model is preferred over the random effects model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time FE vs. Time RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRE vs. RE Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity CRE vs. Entity RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "mean_exog_vars = ['avg' + var for var in exog_vars]\n",
    "\n",
    "hypothesis = \" = \".join(exog_vars + mean_exog_vars) + \" = 0\"\n",
    "wald_test = entity_cre_fit.wald_test(formula= hypothesis)\n",
    "\n",
    "print(wald_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-Way CRE vs. 2-Way RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo_var = 'LEVERAGE'\n",
    "exog_vars = ['SIZE',\n",
    "             'PROFITABILITY',\n",
    "             'TANG',\n",
    "             'LIQUID',\n",
    "             'MCAP',\n",
    "             'SOLV']\n",
    "\n",
    "mean_exog_vars = ['avg' + var for var in exog_vars]\n",
    "\n",
    "hypothesis_matrix = \" = \".join(mean_exog_vars) + ' = 0'\n",
    "wald_test = tw_cre_fit.wald_test(hypothesis_matrix, use_f= False)\n",
    "\n",
    "print(f\"Wald-Test Statistic for 2-Way Correlated Random Effects: {wald_test.df_denom}\")\n",
    "print(f\"Wald-Test Statistic for 2-Way Correlated Random Effects: {wald_test.statistic[0][0]}\")\n",
    "print(f\"Wald-Test Statistic for 2-Way Correlated Random Effects: {wald_test.pvalue.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Wald-Tests conducted between the random effects and correlated random effects models, we have to reject the linearity constraint hypothesis and conclude that the CRE model is preferred. This is expected as we have already tested and accepted the significance of the within effects in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM Test for 2-Way CRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_cre_entity_stat = marg_LM_stat(restricted_model= entity_cre_fit, how= 'Entity')\n",
    "marg_cre_entity_p = 1 - stats.chi2.cdf(marg_cre_entity_stat, 1)\n",
    "\n",
    "print(f\"Marginal LM Statistic for Entity Correlated Random Effects: {marg_cre_entity_stat}\")\n",
    "print(f\"p-value of Marginal LM test for Entity Correlated Random ffects: {marg_cre_entity_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the LM test conducted between the 2-way and entity correlated random effects, the p-value of 1.0 suggests that a 2-way model should not be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Robust Entity CRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_ols_res.time_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
